# üè† housing-prices-prediction

Application de prediction de prix de biens immobiliers √† partir d'un dataset d'entrainnement r√©cup√©r√© depuis une API.

## üìÅ Structure du projet `housing-prices-prediction`

orga : 

```bash
‚îú‚îÄ‚îÄ airflow
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ dag_housing_orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ dag_load_data_evidently.py
‚îÇ   ‚îú‚îÄ‚îÄ dag_load_to_db_real.py
‚îÇ   ‚îú‚îÄ‚îÄ dag_predict.py
‚îÇ   ‚îú‚îÄ‚îÄ dag_train_real.py
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yaml
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ app
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ model_predict.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ utilisateur.py
‚îÇ
‚îú‚îÄ‚îÄ app_real
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ real_estate_dataset.csv 
‚îú‚îÄ‚îÄ evidently
‚îÇ   ‚îî‚îÄ‚îÄ evidently_dashboard.py
‚îú‚îÄ‚îÄ jenkins
‚îÇ   ‚îú‚îÄ‚îÄ Jenkinsfile.evidently_dashboard
‚îÇ   ‚îú‚îÄ‚îÄ Jenkinsfile.load_to_db
‚îÇ   ‚îú‚îÄ‚îÄ Jenkinsfile.predict
‚îÇ   ‚îú‚îÄ‚îÄ Jenkinsfile.train
‚îÇ   ‚îî‚îÄ‚îÄ Jenkinsfile.load_to_db
‚îÇ    
‚îú‚îÄ‚îÄ mlflow_code
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ MLProject
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ set_model_tag.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ housing_prices_eda.ipynb
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îî‚îÄ‚îÄ load_to_db.py
‚îú‚îÄ‚îÄ test
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.load_to_db
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.train
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.predict
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ test_load_to_db.py
‚îÇ   ‚îú‚îÄ‚îÄ test_train.py
‚îÇ   ‚îî‚îÄ‚îÄ test_evidently_dashboard.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ LDS_block_4_lead.pptx
‚îî‚îÄ‚îÄ requirements.txt

## 1) Chargement de la table housing_prices dans la bdd NeonDB

Cette table est initialis√©e avec un fichier csv qui est le dataset d'entrainnement, la colonne price est renseign√©e la colonne price_predict reste √† null.
Cette insertion en BDD est faite √† l'initialisation du projet par src/load_to_db.py.
Cette table est ensuite mise √† jour avec des DAG Airflow.

En local : python load_to_db.py

## 2) MLFlow sur EC2

http://x.x.x.x:5000/



### suppression de la base MLFlow
```bash
rm mlflow.db
```

### Build de l'image Docker de la partie MLFlow en local pour executer le train.py qui utilise le endpoint train de fastapi
```bash
docker build -t housing-prices-estimator ./mlflow_code 
```

### Run du conteneur de la partie MLFlow
```bash
docker run --rm --env-file .env housing-prices-estimator
```

## 3) Jenkins sur EC2 

http://x.x.x.x:8080/

üõ† Modifier l‚ÄôURL de Jenkins apr√®s red√©marrage EC2
	
	üß© aller dans Jenkins :
	Menu principal > Manage Jenkins > System Configuration
	Modifier le champ ‚ÄúJenkins URL‚Äù :
  Mettre http://<nouvelle-ip>:8080
	Menu principal > Manage Jenkins > Credentials
  Re-uploader le .env dans lequel on a mis √† jour l'ip de MLFlow 

Et dans system -> global properties-> variables d'environnement : http://x.x.x.x:4000/
Re-uploader le .env


```bash
./start_jenkins.sh
./stop_jenkins.sh
```

### Docker en local : 
```bash
docker build -f test/Dockerfile.load_to_db -t test-load .
docker run --rm --env-file .env test-load
```
```bash
docker build -f test/Dockerfile.train -t test-train .
docker run --rm test-train
```
```bash
docker build --no-cache -t housing-prices-prediction -f test/Dockerfile.predict .
docker run --rm housing-api-tests
```

A noter dans le Jenkinsfile.predict on utilise le Dockerfile.predictEC2 car le .env est inject√© √† la diff√©rence en local on utilise le Dockerfile.predict car on prend le .env √† la racine du projet
```bash
curl -X POST http://51.44.177.253:4000/predict \
-H "Content-Type: application/json" \
-d '{"area": 60, "property_type": "apartment", "rooms_number": 3, "zip_code": 75015, "land_area": 0, "garden": false, "garden_area": 0, "equipped_kitchen": true, "full_address": "Rue de Vaugirard, Paris", "building_state": "good"}'

docker build -f test/Dockerfile.evidently_dashboard -t evidently-dashboard-test .
docker run --rm --env-file .env evidently-dashboard-test pytest  
```
Nettoyage du disque : 

```bash
docker container prune
docker image prune -a
docker volume prune
```
puis

```bash
docker build -t myjenkins-blueocean:2.504.2-1 -f Dockerfile .
```

## 4) Airflow sur EC2 

Penser √† changer dans airflow la connexion √† jenkins pour avoir la nouvelle ip.

nano pour cr√©er un fichier sur le serveur : 
nano nom du fichier
ctrl O
entr√©e
ctrl X

## 5) FastAPI et Streamlit dock√©ris√© en local et sur EC2

### FastAPI

### API de pr√©diction

projet : Un r√¥le IAM a √©t√© cr√©√© pour les key aws!
pour le moment il y a un .env sur la EC2, qui ne contient rien de sensible, donc si changement d'ip il faut le modifier : 

POSTGRES_DATABASE=postgresql://neondb_owner:npg_x1bn2gueoPdE@ep-bold-firefly-a2mucnl4-pooler.eu-central-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require
MLFLOW_TRACKING_URI=http://xxxxxx:5000/
API_HOST=http://xxxxxx:4000

Pour executer fastAPI : 

```bash
git pull origin development
```
Modifier le .env sur le serveur (MLflow serveur)


A la racine du projet :

```bash 
#source venv/bin/activate
docker build --no-cache -f app/Dockerfile -t housing-api .
docker run -it --rm -p 4000:4000 housing-api
```

http://x.x.x.x:4000/docs

Arr√™t FastAPI
```bash
ps aux | grep uvicorn
lsof -i :4000

sudo kill -9 pid du root
```

### API real time 

API real time

```bash
docker build -t housing-real-api -f app_real/Dockerfile app_real
docker rm -f housing-real-api
docker run \
  --env-file .env \
  -p 8003:8003 \
  --name housing-real-api \
  housing-real-api
```

http://x.x.x.x:8003/docs

### Streamlit

http://x.x.x.x:8501

```bash
docker build -f app/Dockerfile.streamlit -t est-immo-app ./app
docker run -p 8501:8501 --env-file .env est-immo-app
```

### Git

Rappel des commandes : 

```bash
git branch
git checkout development
git status
git add .
git commit -m "xxx"
git push
```